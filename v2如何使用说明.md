
# 从零开始，数据集准备请参考nnunet官方文档 https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_format.md 数据集格式
- 一把鼻涕一把泪，都是辛酸史，建议先在小的数据集上（训练集20，验证集10都可以）先跑通，然后再上大数据集，这样才更快。

## 调参（新手不必要，官方提供的参数已经足够）
找到这个脚本nnUNet\nnunetv2\training\nnUNetTrainer\nnUNetTrainer.py
```python 这里的参数可以自己修改，不会修改的就是用默认参数，性能不会差，通常只修改num_epochs = 1000 足够
### Some hyperparameters for you to fiddle with
self.initial_lr = 1e-2  # 初始学习率
self.weight_decay = 3e-5
self.oversample_foreground_percent = 0.33
self.num_iterations_per_epoch = 250
self.num_val_iterations_per_epoch = 50
self.num_epochs = 1000  # 模型轮次，最少1000，具体可参考官方论文
self.current_epoch = 0
self.enable_deep_supervision = True
```

# 设置环境变量（必须在训练前先指定环境变量，并按照要求放置和设计数据集，不然指令找不到数据集位置）  （推荐,必须有）
- 鉴于我都是在本地windows跑通后，再在外部linx服务器上训练，所以我提供了包括windows和linx的简单的临时环境变量设置.
- 别忘了新建三个文件夹，这三个文件夹干什么的，
```md 
参考：
路径设置：https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/setting_up_paths.md 
- 就是新建三个文件夹在你想要的路径上nnUNet_raw、nnUNet_preprocessed、nnUNet_results

环境变量设置：https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/set_environment_variables.md
- 就是给刚才新建的文件夹指定环境变量，让计算机知道你的文件地址在哪，不要跟你一样找不到（哈哈）

conda create mynnu python=3.10 torch≥2.2.0
PyTorch version: 2.2.0+cu118
Python version: 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]

# windows 
# python [paths.py](nnunetv2%2Fpaths.py)顶端
import os
os.environ['nnUNet_raw'] = r"F:\nnUNet_raw"
os.environ['nnUNet_preprocessed'] = r"F:\nnUNet_preprocessed"
os.environ['nnUNet_results'] = r"F:\nnUNet_results"

# Windows 终端（CMD）中
set nnUNet_raw=F:\nnUNet_raw
set nnUNet_preprocessed=F:\nnUNet_preprocessed
set nnUNet_results=F:\nnUNet_results

# Python 终端
$env:nnUNet_raw="F:\nnUNet_raw"
$env:nnUNet_preprocessed="F:\nnUNet_preprocessed"
$env:nnUNet_results="F:\nnUNet_results"

## 另外，可以在脚本中添加代码来打印环境变量以确保它们被正确设置：
print("nnUNet_raw:", os.environ.get('nnUNet_raw'))
print("nnUNet_preprocessed:", os.environ.get('nnUNet_preprocessed'))
print("nnUNet_results:", os.environ.get('nnUNet_results'))

# linx

conda activate mynnu
pip install nnunetv2
pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git

export nnUNet_raw=/root/autodl-tmp/nnUNet_raw
export nnUNet_preprocessed=/root/autodl-tmp/nnUNet_preprocessed
export nnUNet_results=/root/autodl-tmp/nnUNet_results

```

# 准备数据聚集 （推荐）
## 1.myconvert_dataset.py / [convert_MSD_dataset.py](nnunetv2%2Fdataset_conversion%2Fconvert_MSD_dataset.py)
官方提供的 nnUNet\nnunetv2\dataset_conversion\convert_MSD_dataset.py 脚本就已经实现了数据集命名
说白了，就是加上"_0000"后缀（CT模态），其他模态以此类推

```md
转换前图像名称 RibFrac1-image.nii.gz -> 转换后为 RibFrac1-image_0000.nii.gz ，仅此而已，_0000代表我用的是ct的channel_names， 以前称为 'modality'。作者不喜欢这个名字，所以现在是 channel_names。所以不为什么，接受它。
```

至于什么模态对应什么后缀，参考官方的 nnUNet\nnunetv2\dataset_conversion\generate_dataset_json.py 这个文件，里面备注了一段话，如
```通道名称必须将索引映射到通道名称，例如：
        {
            0: 'T1',
            1: 'CT'
        }
        请注意，通道名称可能会影响归一化方案！！请在文档中了解更多信息。
        ...
```
我看英文麻烦，就搞成了中文 mygenerate_dataset_json.py 文件，顺便稍微改了一下，修改好后指定输出文件夹，直接得到运行所需的json文件
* 注意：[myconvert_dataset.py](nnunetv2/dataset_conversion/myconvert_dataset.py)和[mygenerate_dataset_json.py](nnunetv2/dataset_conversion/mygenerate_dataset_json.py)文件都放置在[dataset_conversion](nnunetv2/dataset_conversion)文件下

## 2.mygenerate_dataset_json.py 用来生成训练的json文件，这个文件是自定义的，说实话，你手打json文件都行，但是要符合官方的规定格式，通道命名方式
- https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_format.md 参考这里，觉得麻烦，你手打配置文件都行，只要按照格式来（哈哈哈），还是用python吧，用llm（如GPT或者免费的）帮你一下，改个文件名字的代码什么的还是很简单的

```python
# 调用函数生成 dataset.json 文件
output_folder = r"F:\nnUNet_raw\Dataset520_Rib"
channel_names = {
    0: "CT"  # 假设你的图像类型是CT
}
labels = {
    "background": 0,  
    "rib_fracture": 1,  # 目标，类别1
}
num_training_cases = 20 # 总共数据集数目，必须有（包括训练和验证，模型自动按照4:1划分为训练和验证）
num_test_cases = 10  # 测试集数目，可不写（后续模型训练好部署后可用来推理）
file_ending = ".nii.gz"  # 文件后缀（格式）
dataset_name = "Rib Fracture Dataset"  # 自定义数据集名称
description = "This dataset contains rib fracture annotations for training nnU-Net models."  # 自定义描述，可不写
generate_dataset_json(output_folder, channel_names, labels, num_training_cases, num_test_cases, file_ending, dataset_name=dataset_name, description=description)
```
代码放置位置：
找到 nnUNet\nnunetv2 
  - [dataset_conversion]
            - 官方 [generate_dataset_json.py]
            - 放置我的修改版 [mygenerate_dataset_json.py]
            - 官方[convert_MSD_dataset.py]
            - 放置我的修改版 [myconvert_dataset.py] 
  - 初始图像命名：RibFrac1-image.nii.gz ，初始label命名 ：RibFrac1-label.nii.gz
  - nnunet图像命名：RibFrac1-image_0000.nii，nnunet的label命名：RibFrac1-image.nii


# 实验规划和预处理 （推荐）
给定一个新的数据集，nnU-Net 将提取数据集指纹（一组特定于数据集的属性，例如图像大小、体素间距、强度信息等）。
此信息用于设计三种 U-Net 配置。这些管道中的每一个都对其自己的数据集预处理版本进行操作。

运行指纹提取、实验规划和预处理的最简单方法是使用：
```md
nnUNetv2_plan_and_preprocess -d DATASET_ID --verify_dataset_integrity
或者多个同时
nnUNetv2_plan_and_preprocess -d 11 12 13 ... --verify_dataset_integrity
```
[nnunetv2\experiment_planning\verify_dataset_integrity.py]验证标签是否符合预期

```bash
nnUNetv2_plan_and_preprocess -d 505 --verify_dataset_integrity
nnUNetv2_plan_and_preprocess -d 510 --verify_dataset_integrity
nnUNetv2_plan_and_preprocess -d 510 -pl nnUNetPlannerResEncL --verify_dataset_integrity
nnUNetv2_plan_and_preprocess -d 520 -pl nnUNetPlannerResEncL --verify_dataset_integrity 

```
```BASH 这里是插曲，可以先不看，先看后面的，这里讲的是residual残差变体，需要更大的gpu内存（先跳过，想进阶的再看） （推荐，可作为后续精度升级，在现有的变体中性价比数一数二了，可参考nnunet官方的论文，我就不放链接了）
## 如何使用新预先

我们提供了三个新的预设，每个预设针对各自的GPU显存和计算预算：

- `nnU-Net ResEnc M` : 类似于标准UNet配置的GPU预算。其中具有9-11GB显存的GPU。训练时间：A100上约12小时
- `nnU-Net ResEnc L` : 需要具有24GB显存的GPU。训练时间：A100上约35小时
- `nnU-Net ResEnc XL` : 需要具有40GB显存的GPU。训练时间：A100上约66小时

使用新预设进行实验计划和预处理：
nnUNetv2_plan_and_preprocess -d 505 -pl nnUNetPlannerResEncM --verify_dataset_integrity
nnUNetv2_plan_and_preprocess -d 510 -pl nnUNetPlannerResEncL --verify_dataset_integrity
nnUNetv2_plan_and_preprocess -d 510 -pl nnUNetPlannerResEncL

运行实验计划（如果已完成预处理）：
nnUNetv2_plan_experiment -d 505 -pl nnUNetPlannerResEncM
nnUNetv2_plan_experiment -d 510 -pl nnUNetPlannerResEncL

2. 现在，只需在运行`nnUNetv2_train`，`nnUNetv2_predict`等时指定正确的计划。[所有nnU-Net命令的接口都是一致的]：
`-p nnUNetResEncUNet(M/L/XL)Plans : -p nnUNetResEncUNetMPlans 、 -p nnUNetResEncUNetLPlans`

训练模型：
nnUNetv2_train -d 510 -c CONFIGURATION -p nnUNetResEncUNetLPlans

进行预测：
nnUNetv2_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -d 510 -c CONFIGURATION -p nnUNetResEncUNetLPlans
```

DATASET_ID数据集 ID 在哪里（呃）。我们建议--verify_dataset_integrity您在第一次运行此命令时执行此操作。这将检查一些最常见的错误源！

您还可以通过提供 来一次处理多个数据集-d 1 2 3 [...]。如果您已经知道需要什么 U-Net 配置，您也可以使用 来指定-c 3d_fullres（在这种情况下请确保适应 -np！）。有关所有可用选项的更多信息，请运行nnUNetv2_plan_and_preprocess -h。

nnUNetv2_plan_and_preprocess 将在 nnUNet_preprocessed 文件夹中创建一个以数据集命名的新子文件夹。命令完成后，将有一个 dataset_fingerprint.json 文件以及一个 nnUNetPlans.json 文件供您查看（如果您感兴趣的话！）。还将有子文件夹包含您的 UNet 配置的预处理数据。

[可选] 如果您希望将所有内容分开，您也可以使用`nnUNetv2_extract_fingerprint`,`nnUNetv2_plan_experiment` 和`nnUNetv2_preprocess`（按此顺序）。

## 模型训练 （直接在这接着看）  （推荐）
概述
您选择要训练哪些配置（2d、3d_fullres、3d_lowres、3d_cascade_fullres）！如果您不知道哪种配置最适合您的数据，只需运行所有配置，然后让 nnU-Net 识别最佳配置。一切由您决定！

nnU-Net 在训练案例中对所有配置进行 5 倍交叉验证。这是必要的，因为 1) nnU-Net 可以估计每种配置的性能并告诉您应该使用哪种配置来解决分割问题；2) 这是一种获得良好模型集成（对这 5 个模型的输出进行平均以进行预测）的自然方法，可以提高性能。

您可以影响 nnU-Net 用于 5 倍交叉验证的分割（请参阅此处）。如果您希望在所有训练案例上训练单个模型，这也是可能的（请参阅下文）。

请注意，并非所有 U-Net 配置都是为所有数据集创建的。在图像尺寸较小的数据集中，U-Net 级联（以及 3d_lowres 配置）被省略，因为全分辨率 U-Net 的块大小已经覆盖了输入图像的很大一部分。

训练模型是通过nnUNetv2_train命令完成的。该命令的一般结构是：
```bash
nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD [additional options, see -h]

nnUNetv2_train DATASET_NAME_OR_ID 2d、3d_fullres、3d_lowres、3d_cascade_lowres FOLD
```
```bash （推荐）
nnUNetv2_train 510 2d 0 1 2 3 4
error: unrecognized arguments: 1 2 3 4 连着不行

nnUNetv2_train 505 2d 0 -p nnUNetResEncUNetMPlans

nnUNetv2_train 510 2d 0 -p nnUNetResEncUNetLPlans
nnUNetv2_train 510 2d 1 -p nnUNetResEncUNetLPlans
nnUNetv2_train 510 2d 2 -p nnUNetResEncUNetLPlans
nnUNetv2_train 510 2d 3 -p nnUNetResEncUNetLPlans
nnUNetv2_train 510 2d 4 -p nnUNetResEncUNetLPlans

cuda:24913M（L40）：
nnUNetv2_train 510 3d_fullres 0  -p nnUNetResEncUNetLPlans
nnUNetv2_train 510 3d_fullres 1  -p nnUNetResEncUNetLPlans
nnUNetv2_train 510 3d_fullres 2  -p nnUNetResEncUNetLPlans
nnUNetv2_train 510 3d_fullres 3  -p nnUNetResEncUNetLPlans
nnUNetv2_train 510 3d_fullres 4  -p nnUNetResEncUNetLPlans

cuda:22876M（3090）
nnUNetv2_train 520 3d_fullres 0  -p nnUNetResEncUNetLPlans
nnUNetv2_train 520 3d_fullres 1  -p nnUNetResEncUNetLPlans
nnUNetv2_train 520 3d_fullres 2  -p nnUNetResEncUNetLPlans
nnUNetv2_train 520 3d_fullres 3  -p nnUNetResEncUNetLPlans
nnUNetv2_train 520 3d_fullres 4  -p nnUNetResEncUNetLPlans

训练全部5折后 
```
[training_log.txt] 记录 nnUNetv2_train和val过程。

UNET_CONFIGURATION 是一个字符串，用于标识所请求的 U-Net 配置（默认值：2d、3d_fullres、3d_lowres、3d_cascade_lowres）。DATASET_NAME_OR_ID 指定应在哪个数据集上进行训练，FOLD 指定训练 5 倍交叉验证中的哪一倍。

`--c` nnU-Net 每 50 个 epoch 存储一个检查点。如果您需要继续之前的训练，只需在训练命令中添加即可。

重要提示：如果您计划使用`nnUNetv2_find_best_configuration`（见下文），请添加该`--npz`标志。这会使 nnU-Net `在最终验证期间保存 softmax 输出`。
它们是必需的。导出的 softmax 预测非常大，因此会占用大量磁盘空间，这就是为什么默认情况下不启用此功能的原因。
如果您最初运行时没有该标志，--npz但现在需要 softmax 预测，只需使用以下命令重新运行验证：

```bash
nnUNetv2_train DATASET_NAME_OR_ID UNET_CONFIGURATION FOLD --val --npz

nnUNetv2_train 510 2d/3d_fullres/3d_lowres/3d_cascade_lowres 0/1/2/3/4 --val --npz
```
```bash （推荐）
nnUNetv2_train 510 2d 0 --val --npz
nnUNetv2_train 510 2d 1 --val --npz
nnUNetv2_train 510 2d 2 --val --npz
nnUNetv2_train 510 2d 3 --val --npz
nnUNetv2_train 510 2d 4 --val --npz

nnUNetv2_train 510 3d_fullres 0  -p nnUNetResEncUNetLPlans --val --npz
nnUNetv2_train 510 3d_fullres 1  -p nnUNetResEncUNetLPlans --val --npz
nnUNetv2_train 510 3d_fullres 2  -p nnUNetResEncUNetLPlans --val --npz
nnUNetv2_train 510 3d_fullres 3  -p nnUNetResEncUNetLPlans --val --npz
nnUNetv2_train 510 3d_fullres 4  -p nnUNetResEncUNetLPlans --val --npz


在 [validation] 文件中生成验证集的 .npz + .pkl 文件
nnUNetv2_train 520 3d_fullres 0  -p nnUNetResEncUNetLPlans --val --npz
nnUNetv2_train 520 3d_fullres 1  -p nnUNetResEncUNetLPlans --val --npz
nnUNetv2_train 520 3d_fullres 2  -p nnUNetResEncUNetLPlans --val --npz
nnUNetv2_train 520 3d_fullres 3  -p nnUNetResEncUNetLPlans --val --npz
nnUNetv2_train 520 3d_fullres 4  -p nnUNetResEncUNetLPlans --val --npz

```
[training_log.txt]记录每折 --val --npz 结果，主要为 Mean Validation Dice:  0.78...

您可以使用 指定 nnU-net 应使用的设备-device DEVICE。DEVICE 只能是 cpu、cuda 或 mps。如果您有多个 GPU，请选择使用 gpu id CUDA_VISIBLE_DEVICES=X nnUNetv2_train [...]（要求设备为 cuda）。
请nnUNetv2_train -h参阅其他选项。

## 2D U-Net
对于 [0, 1, 2, 3, 4] 中的 FOLD，运行：
```bash
nnUNetv2_train DATASET_NAME_OR_ID 2d FOLD [--npz]
```

## 3D全分辨率U-Net (推荐，适用于大部分医学影像场景，我读的是CT，所以用的CT比较多，这个首选了)
对于 [0, 1, 2, 3, 4] 中的 FOLD，运行：
```bash
nnUNetv2_train DATASET_NAME_OR_ID 3d_fullres FOLD [--npz]
```

# 3D U-Net 级联
## 3D低分辨率U-Net
对于 [0, 1, 2, 3, 4] 中的 FOLD，运行：
```bash
nnUNetv2_train DATASET_NAME_OR_ID 3d_lowres FOLD [--npz]
```

## 3D全分辨率U-Net 
对于 [0, 1, 2, 3, 4] 中的 FOLD，运行：
```bash
nnUNetv2_train DATASET_NAME_OR_ID 3d_cascade_fullres FOLD [--npz]
```
请注意，级联的 3D 全分辨率 U-Net 需要低分辨率 U-Net 的五次折叠才能完成！

训练好的模型将被写入 nnUNet_results 文件夹。每次训练都会获得一个自动生成的输出文件夹名称：

[nnUNet_results/DatasetXXX_MYNAME/TRAINER_CLASS_NAME__PLANS_NAME__CONFIGURATION/FOLD]

例如，对于 Dataset002_Heart（来自 MSD），它看起来像这样：

nnUNet_results/
├── Dataset002_Heart
    │── nnUNetTrainer__nnUNetPlans__2d
    │    ├── fold_0
    │    ├── fold_1
    │    ├── fold_2
    │    ├── fold_3
    │    ├── fold_4
    │    ├── dataset.json
    │    ├── dataset_fingerprint.json
    │    └── plans.json
    └── nnUNetTrainer__nnUNetPlans__3d_fullres
         ├── fold_0
         ├── fold_1
         ├── fold_2
         ├── fold_3
         ├── fold_4
         ├── dataset.json
         ├── dataset_fingerprint.json
         └── plans.json

注意这里不存在 3d_lowres 和 3d_cascade_fullres，因为这个数据集没有触发级联。在每个模型训练输出文件夹（每个 fold_x 文件夹）中，将创建以下文件：

- debug.json：包含用于训练此模型的蓝图和推断参数的摘要以及一堆其他内容。不太容易阅读，但对于调试非常有用 ;-)
- checkpoint_best.pth：训练期间确定的最佳模型的检查点文件。目前不使用，除非您明确告诉 nnU-Net 使用它。
- checkpoint_final.pth：最终模型的检查点文件（训练结束后）。这用于验证和推理。
- network_architecture.pdf（仅当安装了 hiddenlayer 时！）：一个包含网络架构图的 pdf 文档。
- progress.png：显示训练过程中的损失、伪骰子、学习率和时期时间。顶部是训练期间的训练（蓝色）和验证（红色）损失的图。还显示了骰子的近似值（绿色）及其移动平均值（绿色虚线）。这个近似值是前景类的平均骰子分数。它需要非常谨慎地对待，因为它是在每个时期结束时从验证数据中随机抽取的补丁上计算的，并且骰子计算的 TP、FP 和 FN 的聚合将补丁视为它们都来自同一体积（“全局骰子”；我们不会为每个验证案例计算一个骰子，然后对所有案例进行平均，而是假装只有一个验证案例，我们从中抽取补丁）。这样做的原因是“全局骰子”在训练期间很容易计算，并且对于评估模型是否正在训练仍然非常有用。每个时期进行适当的验证需要花费太长时间。验证在训练结束时进行。
- validation_raw：此文件夹中是训练完成后预测的验证案例。此处的 summary.json 文件包含验证指标（文件开头提供了所有案例的平均值）。如果--npz已设置，则压缩的 softmax 输出（保存为 .npz 文件）也在此处。

在训练期间，观察进度通常很有用。因此，我们建议您在运行第一次训练时查看生成的 progress.png。它将在每个时期后更新。

训练时间很大程度上取决于 GPU。我们推荐用于训练的最小 GPU 是 Nvidia RTX 2080ti。有了它，所有网络训练只需不到 2 天的时间。请参阅我们的基准测试，看看您的系统是否按预期运行。

使用多个 GPU 进行训练
如果您有多个 GPU，那么最好的使用方法是同时训练多个 nnU-Net 训练，每个 GPU 上一个。这是因为数据并行性永远不会完美地线性扩展，尤其是对于 nnU-Net 使用的小型网络。

例子：
```bash  (没用过，我发现训练一折和五折推理差不多，可能是我眼花，还是训练五折把，不过很费钱...)
CUDA_VISIBLE_DEVICES=0 nnUNetv2_train DATASET_NAME_OR_ID 2d 0 [--npz] & # train on GPU 0
CUDA_VISIBLE_DEVICES=1 nnUNetv2_train DATASET_NAME_OR_ID 2d 1 [--npz] & # train on GPU 1
CUDA_VISIBLE_DEVICES=2 nnUNetv2_train DATASET_NAME_OR_ID 2d 2 [--npz] & # train on GPU 2
CUDA_VISIBLE_DEVICES=3 nnUNetv2_train DATASET_NAME_OR_ID 2d 3 [--npz] & # train on GPU 3
CUDA_VISIBLE_DEVICES=4 nnUNetv2_train DATASET_NAME_OR_ID 2d 4 [--npz] & # train on GPU 4
...
wait
```
## 重要提示：第​​一次运行训练时，nnU-Net 会将预处理数据提取到未压缩的 numpy 数组中，以提高速度！此操作必须在开始相同配置的多个训练之前完成！等待第一次训练使用 GPU 后再开始后续折叠！根据数据集大小和您的系统，这最多只需要几分钟。

如果您坚持运行 DDP 多 GPU 训练，我们可以为您提供帮助：

`nnUNetv2_train DATASET_NAME_OR_ID 2d 0 [--npz] -num_gpus X`

再次注意，这比在单独的 GPU 上运行单独的训练要慢。仅当您手动干预 nnU-Net 配置并使用更大的补丁和/或批量大小训练更大的模型时，DDP 才有意义！

使用时重要`-num_gpus`：

- 如果您使用 2 个 GPU 进行训练，但系统中有更多 GPU，则需要通过 CUDA_VISIBLE_DEVICES=0,1（或任何您的 ID）指定应使用哪些 GPU。
- 您指定的 GPU 数量不能超过小批量中的样本数量。如果批量大小为 2，则最多为 2 个 GPU！
- 确保您的批量大小可以被您使用的 GPU 数量整除，否则您将无法充分利用您的硬件。
与旧版 nnU-Net 相比，DDP 现在完全没有麻烦。尽情享受吧！

# 自动确定最佳配置 (推荐)

一旦所需的配置经过训练（完全交叉验证），您就可以告诉 nnU-Net 自动为您识别最佳组合：

```bash 这需要包含验证集预测概率的 .npz 文件存在和完全交叉验证。  生成 crossval_results_folds_0_1_2_3_4. 文件
nnUNetv2_find_best_configuration DATASET_NAME_OR_ID -c CONFIGURATIONS 
nnUNetv2_find_best_configuration 520 -c 3d_fullres -p nnUNetResEncUNetLPlans 
nnUNetv2_find_best_configuration 510 -c 3d_fullres -p nnUNetResEncUNetLPlans 

```
生成[crossval_results_folds_0_1_2_3_4]文件。[[crossval_results_folds_0_1_2_3_4].md]

`CONFIGURATIONS`以下是您想要探索的`配置列表`。默认情况下，集成处于启用状态，这意味着 `nnU-Net 将生成所有可能的集成组合（每个集成 2 个配置）`。

这需要包含验证集预测概率的 .npz 文件存在（`nnUNetv2_train`与 `--npz`标志一起使用，见上文）。您可以通过设置标志来禁用集成`--disable_ensembling`。

查看`nnUNetv2_find_best_configuration -h`更多选项。

`nnUNetv2_find_best_configuration` 还[将自动确定应使用的后处理]。
nnU-Net 中的[后处理仅考虑删除预测中除最大组件之外的所有组件]（一次针对前景与背景，一次针对每个标签/区域）。
完成后，[该命令将打印到控制台，准确显示您需要运行哪些命令来进行预测]。

它还将在[nnUNet_results/DATASET_NAME]文件夹中创建两个文件供您检查：

# json/txt:
[nnUNet_results/Dataset520_Rib/inference_instructions.txt]再次包含预测所需的确切命令
[nnUNet_results/Dataset520_Rib/inference_information.json]可以检查所有配置和集合的性能，以及后处理的效果和一些调试信息。

## 运行推理 

请记住，输入文件夹中的数据必须具有与您训练模型的数据集相同的文件结尾，并且必须遵守图像文件的 nnU-Net 命名方案（请参阅数据集格式和 推理数据格式！）

`nnUNetv2_find_best_configuration`（见上文）将向终端打印一个字符串，其中包含您需要使用的推理命令。运行推理的最简单方法就是使用这些命令。

如果您希望手动指定用于推理的配置，请使用以下命令：

###  运行预测 (推荐)
对于每个所需的配置，运行：
```bash 请注意，默认情况下，推理将使用交叉验证中的所有 5 个折叠作为整体进行。我们强烈建议您使用所有 5 个折叠。因此，在运行推理之前，必须先训练所有 5 个折叠。
[inference_instructions.txt]:
nnUNetv2_predict -d Dataset520_Rib -i INPUT_FOLDER -o OUTPUT_FOLDER -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetResEncUNetLPlans
nnUNetv2_predict -d Dataset520_Rib -i /root/autodl-tmp/nnUNet_raw/Dataset520_Rib/imagesTs -o /root/autodl-tmp/OUTPUT_FOLDER -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetResEncUNetLPlans
nnUNetv2_predict -d Dataset510_Rib -i /root/autodl-tmp/nnUNet_raw/Dataset520_Rib/imagesTs -o /root/autodl-tmp/OUTPUT_FOLDER -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetResEncUNetLPlans

若要使用集成，指定`--save_probabilities`：
nnUNetv2_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -d DATASET_NAME_OR_ID -c CONFIGURATION --save_probabilities -p nnUNetResEncUNetLPlans
```
Only specify `--save_probabilities` if you intend to use [ensembling]. 
`--save_probabilities` will make the command save the predicted probabilities alongside of the predicted segmentation masks requiring a lot of disk space.
`--save_probabilities`仅当您打算使用[集成ensemble]时才指定。`--save_probabilities`将使命令保存预测概率以及预测的分割掩码，从而需要大量磁盘空间。

Please select a separate OUTPUT_FOLDER for each configuration![3d_fullres:OUTPUT_FOLDER1 ; 2d:OUTPUT_FOLDER2 ...]
请为每个配置选择一个单独的 OUTPUT_FOLDER！

Note that per default, inference will be done with all 5 folds from the cross-validation as an ensemble. We very strongly recommend you use all 5 folds. Thus, all 5 folds must have been trained prior to running inference.
请注意默认情况下，推理将使用交叉验证中的所有 5 个折叠作为一个集成ensemble进行。我们强烈建议您使用所有 5 个折叠。因此，在运行推理之前，必须先训练所有 5 个折叠。

If you wish to make predictions with a single model, train the [all] fold and specify it in [nnUNetv2_predict] with [-f all]
如果你希望使用单个模型进行预测，请训练折叠all并nnUNetv2_predict在-f all.

## 集成多个配置的预测 Ensembling multiple configurations（这个我没有用过，因为我只涉及3D全卷积网络的训练，这里好像是可以继承不同配置的模型来一起推理，不过增加那么一点dice，我觉得还是算了，性价比不高）

If you wish to ensemble multiple predictions (typically form different configurations), you can do so with the following command:
如果您希望集成多个预测（通常来自不同的配置，如2d、3d），您可以使用以下命令进行：
```bash
nnUNetv2_predict -i INPUT_FOLDER -o FOLDER1 -d DATASET_NAME_OR_ID -c CONFIGURATION --save_probabilities -p nnUNetResEncUNetLPlans
nnUNetv2_predict -i INPUT_FOLDER -o FOLDER2 -d DATASET_NAME_OR_ID -c CONFIGURATION --save_probabilities -p nnUNetResEncUNetLPlans
...

nnUNetv2_ensemble -i FOLDER1 FOLDER2 ... -o OUTPUT_FOLDER -np NUM_PROCESSES -p nnUNetResEncUNetLPlans

```
You can specify an arbitrary number of folders, but remember that each folder needs to contain npz files that were generated by nnUNetv2_predict. Again, nnUNetv2_ensemble -h will tell you more about additional options.
您可以指定任意数量的文件夹，但请记住每个文件夹都需要包含由 nnUNetv2_predict 生成的 npz 文件。同样，nnUNetv2_ensemble -h 将告诉您有关其他选项的更多信息。

usage: nnUNetv2_ensemble [-h] -i I [I ...] -o O [-np NP] [--save_npz]
options:
  -h, --help    show this help message and exit
  -i I [I ...]  list of input folders
  -o O          output folder
  -np NP        Numbers of processes used for ensembling. Default: 8
  --save_npz    Set this flag to store output probabilities in separate .npz files 设置此标志可将输出概率存储在单独的 .npz 文件中

### 应用后处理  (可推荐，我发现没啥区别，原文也将只是在某些任务上表现有点改进...)
最后，将之前确定的后处理应用于（集成的）预测：
```bash
nnUNetv2_apply_postprocessing -i FOLDER_WITH_PREDICTIONS -o OUTPUT_FOLDER --pp_pkl_file POSTPROCESSING_FILE -plans_json PLANS_FILE -dataset_json DATASET_JSON_FILE

nnUNetv2_apply_postprocessing -i /root/autodl-tmp/OUTPUT_FOLDER -o /root/autodl-tmp/OUTPUT_FOLDER_PP -pp_pkl_file /root/autodl-tmp/nnUNet_results/Dataset520_Rib/nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres/crossval_results_folds_0_1_2_3_4/postprocessing.pkl -np 8 -plans_json /root/autodl-tmp/nnUNet_results/Dataset520_Rib/nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres/crossval_results_folds_0_1_2_3_4/plans.json

```
nnUNetv2_find_best_configuration (or its generated [inference_instructions.txt] file) will tell you where to find the postprocessing file. 
If not you can just look for it in your results folder (it's creatively named [postprocessing.pkl]).
nnUNetv2_find_best_configuration（或其生成的 [inference_instructions.txt] 文件）将告诉您在哪里可以找到后处理文件。如果没有，您可以在结果文件夹中查找它（它的创意名称是 [postprocessing.pkl]）。

[If your source folder is from an ensemble], you also need to specify a -plans_json file and a -dataset_json file that should be used 
(for single configuration predictions these are automatically copied from the respective training). 
[如果您的源文件夹来自一个集合]，您还需要指定应该使用的 -plans_json 文件和 -dataset_json 文件（对于单一配置预测，这些文件会自动从相应的训练中复制）。
You can pick these files from any of the ensemble members.

-pp_pkl_file [crossval_results_folds_0_1_2_3_4/postprocessing.pkl]
-plans_json [crossval_results_folds_0_1_2_3_4/plans.json]

## 如何使用预训练模型部署和运行推理 (推荐)

为了方便在不同的计算机上使用预训练模型进行推理，请遵循以下简化步骤：

导出模型：利用该`nnUNetv2_export_model_to_zip`功能将训练好的模型打包成`.zip `文件。此文件将包含所有必要的模型文件。
传输模型：将`.zip `文件传输到将执行推理的目标计算机。
导入模型：在新电脑上，使用`nnUNetv2_install_pretrained_model_from_zip`从 `.zip` 文件加载预训练模型。
请注意，两台计算机都必须安装 nnU-Net 及其所有依赖项，以确保模型的兼容性和功能。
```bash
nnUNetv2_export_model_to_zip [-h] -d D -o O [-c C [C ...]] [-tr TR] [-p P] [-f F [F ...]] [-chk CHK [CHK ...]] [--not_strict] [--exp_cv_preds]

nnUNetv2_export_model_to_zip -d 510 -o dataset510_model.zip -c 3d_fullres -tr nnUNetTrainer -p nnUNetResEncUNetLPlans -f 0 1 2 3 4 --exp_cv_preds 

```
usage: nnUNetv2_export_model_to_zip [-h] -d D -o O [-c C [C ...]] [-tr TR] [-p P] [-f F [F ...]] [-chk CHK [CHK ...]] [--not_strict] [--exp_cv_preds]
Use this to export a trained model as a zip file.
options:
  -h, --help          show this help message and exit
  -d D                Dataset name or id
  -o O                Output file name
  -c C [C ...]        List of configuration names
  -tr TR              Trainer class
  -p P                plans identifier
  -f F [F ...]        list of fold ids
  -chk CHK [CHK ...]  Lis tof checkpoint names to export. Default: checkpoint_final.pth
  --not_strict        Set this to allow missing folds and/or configurations
  --exp_cv_preds      Set this to export the cross-validation predictions as well


```bash
(mynnu) PS F:\> 
nnUNetv2_install_pretrained_model_from_zip dataset520_model.zip

nnUNetv2_install_pretrained_model_from_zip dataset510_model.zip

```
自动解压到环境变量[nnUNet_results\Dataset520_Rib]

usage: nnUNetv2_install_pretrained_model_from_zip [-h] zip
Use this to install a zip file containing a pretrained model.
positional arguments:
  zip         zip file
options:
  -h, --help  show this help message and exit

```bash
***Run inference like this:***

nnUNetv2_predict -d Dataset520_Rib -i "F:\nnUNet_raw\Dataset520_Rib\imagesTs" -o OUTPUT_FOLDER -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetResEncUNetLPlans
nnUNetv2_predict -d Dataset510_Rib -i "F:\nnUNet_raw\Dataset510_Rib\imagesTs" -o OUTPUT_FOLDER\labelsTs_160 -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetResEncUNetLPlans
nnUNetv2_predict -d Dataset510_Rib -i "F:\imagesTs_SHUAI" -o OUTPUT_FOLDER\labelsTs_SHUAI_149 -f  0 1 2 3 4 -tr nnUNetTrainer -c 3d_fullres -p nnUNetResEncUNetLPlans
nnUNetv2_predict -d Dataset510_Rib -i "F:\Dataset531_RibFRAC" -o OUTPUT_FOLDER\labelsTs_RibFRAC_219_f0 -f  0 -tr nnUNetTrainer -c 3d_fullres -p nnUNetResEncUNetLPlans

***Once inference is completed, run postprocessing like this:***

nnUNetv2_apply_postprocessing -i OUTPUT_FOLDER\labelsTs_160 -o OUTPUT_FOLDER_PP\labelsTs_160 -pp_pkl_file "F:\nnUNet_results\Dataset510_Rib\nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\postprocessing.pkl" -np 8 -plans_json "F:\nnUNet_results\Dataset510_Rib\nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\plans.json"
nnUNetv2_apply_postprocessing -i OUTPUT_FOLDER\labelsTs_SHUAI_149 -o OUTPUT_FOLDER_PP\labelsTs_SHUAI_149 -pp_pkl_file "F:\nnUNet_results\Dataset510_Rib\nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\postprocessing.pkl" -np 8 -plans_json "F:\nnUNet_results\Dataset510_Rib\nnUNetTrainer__nnUNetResEncUNetLPlans__3d_fullres\crossval_results_folds_0_1_2_3_4\plans.json"

```




